{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction to Pandas.ipynb","version":"0.3.2","provenance":[{"file_id":"1VBSiMvmrmTONm5MXY8VKSMszSFaWwd6p","timestamp":1551437517426},{"file_id":"1NwbWILCQDbnu-2ss9HfRKAj99PmrgCMw","timestamp":1551437480198}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"lhMeSJe6qvX0","colab_type":"text"},"cell_type":"markdown","source":["# Introduction to `pandas`\n","\n","This workshop's goal&mdash;which is facilitated by this `Colab notebook`&mdash;is to give you the confidence to use the `pandas` library in your future projects. You can also explore some of the functionality of the markup language in all the non-code cells like this one, which will allow you to generate presentations using the your own code and its output. Basic familiarity with Python *is* assumed as you should have already completed the first 3 initial projects.\n","\n","The `pandas` library has been designed to facilitate the work with structured data. Most of the analyses you might perform will likely involve using tabular data, e.g., from Excel files, .csv files or relational databases (e.g., SQL). The `DataFrame` object in `pandas` is \"a two-dimensional tabular, column-oriented data structure with both row and column labels.\" We will also take a look at `panas` `Series`, which is the one-dimensional version of the `DataFrame`, which means that is just a vector or a column of data. \n","\n","If you're curious:\n","\n",">The `pandas` name itself is derived from *panel data*, an econometrics term for multidimensional structured data sets, and *Python data analysis* itself. After getting introduced, you can consult the full [`pandas` documentation](http://pandas.pydata.org/pandas-docs/stable/).\n","\n","To motivate this workshop, we'll work with example data and go through the various steps you might need to prepare data for analysis. You'll realize that doing this type of work with large amounts of data is much more easier with `pandas` rather than using the Python's built-in data structures that we saw in the previous workshops like `lists` or `dictionaries`."]},{"metadata":{"id":"yPQ1yxxNrYJF","colab_type":"text"},"cell_type":"markdown","source":["### Table of Contents\n","\n","1 - [The DataFrame](#section1)<br>\n","\n","2 - [Rename, Index, and Slice](#section2)<br>\n","\n","3 - [Manipulating Columns](#section3)<br>\n","\n","4 - [Merging](#section4)<br>\n","\n","5 - [Calculating Unique And Missing Values](#section5)<br>\n","\n","6 - [Groupby](#section6)<br>\n","\n","7- [Exporting To CSV](#section7)<br>\n","\n","8 - [Handling Missing Values (Boolean Indexing)](#section8)<br>\n","\n","9 - [Sorting Values](#section9)<br>\n","\n","10 - [Plotting In Pandas](#section10)<br>"]},{"metadata":{"id":"2vbjp7-grdo0","colab_type":"text"},"cell_type":"markdown","source":["<a id='section1'></a>\n","## 1. The DataFrame: Importing Data and Summary Statistics\n","The data used in these examples is available in the following [GitHub repository](https://github.com/google/dspl/tree/master/datasets/eurostat/unemployment), which is hosted by Google. We've selected a couple of those files and they are available at the Coding Club folder in our Google Drives, under the `data/` folder.\n","\n","The first thing you must do is download the two files into your laptop and load them using the code provided in the previous projects, which you can find again in [here](https://colab.research.google.com/notebooks/io.ipynb)\n","\n","Let's begin by importing `pandas` using the conventional abbreviation &mdash;pd&mdash; and some other libraries to upload and download files from this notebook."]},{"metadata":{"id":"sT-4cZxYqzzB","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wV7y0vsk6tip","colab_type":"text"},"cell_type":"markdown","source":["The following piece of code will allow us to select one or multiple files at once. If we selecte multiple files, the `uploaded` variable will become a `dictionary` type. A dictionary is a collection which is unordered, changeable and indexed. They are declared with curly brackets, and they have keys and values. You can access the items of a `dictionary` by referring to its key name, inside square brackets, as we will do with our first loaded file below."]},{"metadata":{"id":"4DIMMzW0sCOZ","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KtkYX6_tttvA","colab_type":"text"},"cell_type":"markdown","source":["The `read_excel()` function in `pandas` allows us to easily import our data from an Excel file. You can specify the sheet name or number using `sheet_name`.  By default, it will load the first sheet in the notebook, and only that one. You can also specify the columns that you want to load, the number of rows or columns that you want to skip, if the sheet has a header or not, and many other parameters that you can see in the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html). `read_excel()` returns a `DataFrame`, which is the object type that we will be using today."]},{"metadata":{"id":"Q17AovzusrZI","colab_type":"code","colab":{}},"cell_type":"code","source":["import io\n","\n","unemployment = pd.read_excel(io.BytesIO(uploaded['countries_total.xlsx']), sheet_name='Sheet1')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"acL29m5Mu5rB","colab_type":"text"},"cell_type":"markdown","source":["Great! You've created a `pandas` `DataFrame`. We can look at our data by using the `.head()` method. By default, this shows the header (column names) and the first five rows. Passing an integer, $n$, to `.head()` returns that number of rows."]},{"metadata":{"id":"uG25rsTis0fZ","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rWkpsZKwvDF-","colab_type":"text"},"cell_type":"markdown","source":["To find the number of rows, you can use the `len()` function. Alternatively, you can use the `shape` attribute to see the number of rows and columns. If you write in a code cell the name of a variable, or a statement that returns data, `Google Colab` will print by default its content, without needing to use the `print()` function. But remember, this is only true if there is no more code after that line."]},{"metadata":{"id":"cZh2WQr6vKWb","colab_type":"code","colab":{}},"cell_type":"code","source":["len(unemployment)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DDIO8mWWtd4Y","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-OgiUVZXvOpc","colab_type":"text"},"cell_type":"markdown","source":["We have loaded one of the two files and we've also called a property (`shape`) and a method (`head()`)  of our `DataFrame` object. Next, you'll have to load the second file and answer a few questions about it."]},{"metadata":{"id":"jxrElj-fw6MR","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 1: Import and Explore Data From A CSV File\n","\n","The `read_csv()` function in `pandas` allows us to easily import our data from a .csv file. By default, it assumes the data is comma-delimited, but you can specify the delimiter used in your data (e.g., tab, semicolon, pipe, etc.). There are several parameters that you can specify. See the documentation [here](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). `read_csv()` returns a `DataFrame`.\n","\n","Call `read_csv()` using the `pd` abbreviation as we did before and load the `countries.csv` file. Call the resulting `DataFrame` $countries$"]},{"metadata":{"id":"OSAz6pswvJMI","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use the .read_csv to load the second file you uploaded \n","# into a new DataFrame called countries"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MhbG7tX6xYEx","colab_type":"text"},"cell_type":"markdown","source":["Check the last $10$ rows using the method `.tail()`. "]},{"metadata":{"id":"mq-C8KJexO7-","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use the tail method to check the 10 last rows of countries"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Oi7mHXG2xyWk","colab_type":"text"},"cell_type":"markdown","source":["There are some other important methods that will allow you to explore your `DataFrame`. Try using the `info()`, `describe()`. Also, look at two other properties of the `DataFrame`: `dtypes` and `columns`. Do all that in your $countries$ `DataFrame`."]},{"metadata":{"id":"8qb3KRC3xtyg","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use the info() methods on the countries DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2sGl0epSxiWG","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use the describe() methods on the countries DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PINmobs0zRLD","colab_type":"code","colab":{}},"cell_type":"code","source":["# print the dtypes property of the countries DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7gl_35ndzUi5","colab_type":"code","colab":{}},"cell_type":"code","source":["# print the columns property of the countries DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aAAFtlaNzeG9","colab_type":"text"},"cell_type":"markdown","source":["When you called the `describe()` method, you may have noticed that only numeric columns were described. That is because the result of that method depends on what it's called on. If the `DataFrame` includes both numeric and object (e.g., strings) `dtype`s, it will default to summarizing the numeric data. If `.describe()` is called on strings, for example, it will return the count, number of unique values, and the most frequent value along with its count.\n","\n","Also, the \"count\" parameter takes into account only  *non-missing* values, so if there are empty rows in some of the columns, we will see that reflected here."]},{"metadata":{"id":"gh6KQy_n0zGO","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 2: Import Data From A URL\n","\n","Above, we imported the unemployment data using the `read_csv` function from a file that we had previously uploaded to our notebook. `read_csv` is a very flexible method; it also allows us to import data using a URL as the file path. \n","\n","A csv file with data on world countries and their abbreviations is located at [https://raw.githubusercontent.com/dlab-berkeley/introduction-to-pandas/master/data/countries.csv](https://raw.githubusercontent.com/dlab-berkeley/introduction-to-pandas/master/data/countries.csv).\n","\n","Using `read_csv`, import the country data and save it to the variable $countries$ again and check that the content is the same as the file loaded before."]},{"metadata":{"id":"_OEJQC3hzXL3","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use .read_csv() on the link provided to overwrite the countries DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IZia0gP61NLJ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Check the last 10 columns and make sure that they are \n","# the same as we saw before"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MhBYpp651PST","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use the describe method on countries again and check that nothing changes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hsHlkE4X5O7a","colab_type":"text"},"cell_type":"markdown","source":["<a id='section2'></a>\n","## 2. Rename, Index, and Slice\n","Back to the entire unemployment data set. You may have noticed that the `month` column also includes the year. Let's go ahead and rename it."]},{"metadata":{"id":"8eMEAN8r1o27","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment = unemployment.rename(columns={'year_month' : 'month'})"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XuLigeDk5dVP","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"czLYyzod0aiH","colab_type":"text"},"cell_type":"markdown","source":["We'll change again the column name with the original name for now"]},{"metadata":{"id":"JdfA7G9X6N5j","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.rename(columns={'month' : 'year_month'}, inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fWcIw1w16Yzo","colab_type":"text"},"cell_type":"markdown","source":["The `.rename()` method allows you to modify index labels and/or column names. As you can see, we passed a `dictionary` to the `columns` parameter, with the original name as the key and the new name as the value. Importantly, in the second renaming we also set the `inplace` parameter to `True`, which modifies the *actual* `DataFrame`, not a copy of it.\n","\n","It might also make sense to separate the data in `year_month` into two separate columns. To do this, you'll need to know how to select a single column. We can either use bracket (`[]`) or dot notation (referred to as *attribute access*)."]},{"metadata":{"id":"H9yew1aZ6Qon","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment['year_month'].head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KAKPPZUg-pbf","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.year_month.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9xcXgxhE-vm5","colab_type":"text"},"cell_type":"markdown","source":["It is preferrable to use the bracket notation as a column name might inadvertently have the same name as a `DataFrame` (or `Series`) method. In addition, only bracket notation can be used to create a new column. If you try and use attribute access to create a new column, you'll create a new attribute, *not* a new column.\n","\n","When selecting a single column, we have a `pandas` `Series` object, which is a single vector of data, with \"an associated array of data labels, called its *index*.\" A `DataFrame` also has an index. In our example, the indices are an array of sequential integers, which is the default. You can find them in the left-most position, without a column label.\n","\n","Indices need not be a sequence of integers. They can, for example, be dates or strings. Note that indices do *not* need to be unique.\n","\n","Indices, like column names, can be used to select data. Indices can be used to select particular rows. In fact, you can do something like `.head()` with slicing using the `[]` operator."]},{"metadata":{"id":"0sQeoIyf-rC5","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment[0:5]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3Tpl7SoI_szT","colab_type":"text"},"cell_type":"markdown","source":["Before we continue, let's look at a few useful ways to index data&mdash;that is, select rows.\n","\n","`.loc` primarily works with string labels. It accepts a single label, a list (or array) of labels, or a slice of labels (e.g., `'a' : 'f'`).\n","\n","Let's create a `DataFrame` to see how this works."]},{"metadata":{"id":"Lz5La3Hd_g8i","colab_type":"code","colab":{}},"cell_type":"code","source":["bacteria = pd.DataFrame({'bacteria_counts' : [632, 1638, 569, 115],\n","                         'other_feature' : [438, 833, 234, 298]},\n","                         index=['Firmicutes', 'Proteobacteria', \n","                                'Actinobacteria', 'Bacteroidetes'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rhOTjtF-__16","colab_type":"text"},"cell_type":"markdown","source":["Notice that we pass in a `dict`, where the keys correspond to column names and the values to the data. In this example, we've also set the indices&mdash;strings in this case&mdash;to be the taxon of each bacterium."]},{"metadata":{"id":"FiEc0TK__60a","colab_type":"code","colab":{}},"cell_type":"code","source":["bacteria"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YvcBHYe9AFOi","colab_type":"text"},"cell_type":"markdown","source":["Now, if we're interested in the values (row) associated with \"Actinobacteria,\" we can use `.loc` and the index name."]},{"metadata":{"id":"yHMZ3QhqABp3","colab_type":"code","colab":{}},"cell_type":"code","source":["bacteria.loc['Actinobacteria']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NskUFbO4AMuA","colab_type":"text"},"cell_type":"markdown","source":["This returns the column values for the specified row. Interestingly, we could have also used \"positional indexing,\" even though the indices are strings."]},{"metadata":{"id":"2Hy6mBilAHwZ","colab_type":"code","colab":{}},"cell_type":"code","source":["bacteria[2:3]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UyzBNaYhATFe","colab_type":"text"},"cell_type":"markdown","source":["The difference is that the former returns a `Series` because we selected a single lable, while the latter returns a `DataFrame` because we selected a range of positions.\n","\n","Let's return to our unemployment data. Another indexing option, `.iloc`, primarily works with integer positions. To select specific rows, we can do the following."]},{"metadata":{"id":"-1xaZx0xAQWC","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.iloc[[1, 5, 6, 9]]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KlQldmPBAfZc","colab_type":"text"},"cell_type":"markdown","source":["We can select a range of rows and specify the step value."]},{"metadata":{"id":"BS1Dv_hSAWdp","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.iloc[25:50:5]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y-cfgxxmAlBQ","colab_type":"text"},"cell_type":"markdown","source":["(Note: As is typical in Python, the end position is not included. Therefore, we don't see the row associated with the index 50, just as when we used `unemployment[0:5]` to mimic the `head()` method, we didn't receive the row in the index number 5.)\n","\n","Indexing is important. You'll use it a lot. Below, we'll show how to index based on data values."]},{"metadata":{"id":"mXYmDDQDA8b-","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 3: Renaming `bacteria`\n","\n","The \"other_feature\" column in our `bacteria` table isn't very descriptive. Suppose we know that \"other_feature\" refers to a second set of bacteria count observations. Use the `rename` method to give \"other_feature\" a more descriptive name like `second_count`."]},{"metadata":{"id":"Rr9bKv9zAekD","colab_type":"code","colab":{}},"cell_type":"code","source":["# Rename the column as asked and print the full DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TibYprSWBL8n","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 4: Indexing to get a specific value\n","\n","Both `loc` and `iloc` can be used to select a particular value if they are given two arguments. The first argument is the name (when using `loc`) or index number (when using `iloc`) of the *row* you want, while the second argument is the name or index number of the *column* you want.\n","\n","Using `loc`, select \"Bacteroidetes\" and \"bacteria_counts\" to get the first bacteria count of Bacteroidetes.\n","\n","Try getting the same result using `iloc` too."]},{"metadata":{"id":"vyF4DIXa1pEV","colab_type":"code","colab":{}},"cell_type":"code","source":["bacteria"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uSWb0IxUBIZ5","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get the number 115 using .loc()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lTd1jPo4Bj-f","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get the number 115 using .iloc()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NGjCLQM3Bqds","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 5: Indexing multiple rows and columns\n","\n","Both `loc` and `iloc` can be used to select subsets of columns *and* rows at the same time if they are given lists (and/or slices, for `iloc`] as their two arguments. \n","\n","You can use a `list` to get the desired rows and columns but when the numbers are continuous, you can select them with a range like:\n","> test_dataframe.iloc[0:5,] #This will return the first four rows and all the columns for the test_dataframe\n","\n","Using `iloc` on the `unemployment` DataFrame, get:\n","* every row starting at row 4 and ending at row 7\n","* of those rows, only the 1st, 3rd and 4th columns\n","\n","Get exactly those same cells using `loc` too."]},{"metadata":{"id":"zBo1zbp1Blvt","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get rows 4 to 7 of column number 1, 3 and 4 with .iloc()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qu3sq-YyB47H","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get rows 4 to 7 of column number 1, 3 and 4 with .loc()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LDki_CysCRDe","colab_type":"text"},"cell_type":"markdown","source":["Your result should be in both cases equal to this:\n","\n",">![Challenge 5 answer](https://raw.githubusercontent.com/oxanozaep/pandas_learning/master/images/challenge5.jpg)\n","\n","You must have noticed that in order to get the same results, the row numbers differ between both methods. That is because using slices in `.loc` treats the end position in the slice inclusively, while slicing with `.iloc` (and on the DataFrame itself!) treats the end position in the slice exclusively (as Python lists does).\n","\n"]},{"metadata":{"id":"cKISvv5lCjfU","colab_type":"text"},"cell_type":"markdown","source":["<a id='section3'></a>\n","## 3. Manipulating Columns: Renaming, Creating, Reordering"]},{"metadata":{"id":"nadQ-jCWCo0P","colab_type":"text"},"cell_type":"markdown","source":["So, we still want to **split `year_month` into two separate columns.** Above, we saw that this column is type (technically, `dtype`) `float64`. \n","\n","You'll need to extract the year first using the `.astype()` method. This allows for type casting&mdash;basically converting from one type to another. We will call this column `year`.\n","\n","We'll then subtract this value from `year_month`&mdash;to get the decimal portion of the value&mdash;and multiply the result by 100 and convert to `int`. Call this column `month`.\n","\n","For more information on `pandas` `dtype`s, check the documentation [here](http://pandas.pydata.org/pandas-docs/stable/basics.html#dtypes)."]},{"metadata":{"id":"gWXTwViIB7iY","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment['year'] = unemployment['year_month'].astype(int)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wJ_aw7B5C8t7","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment['month'] = ((unemployment['year_month'] - unemployment['year']) * 100).round(0).astype(int)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EALGgP0JDDus","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y1Ub2wrnDbic","colab_type":"text"},"cell_type":"markdown","source":["Now, let's say we wanted to **reorder the columns** in the `DataFrame`. For this, we use bracket notation again, passing in a list of column names in the order we'd like to see them."]},{"metadata":{"id":"ortEv_OcDFRK","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment = unemployment[['country', 'seasonality',\n","                             'year_month', 'year', 'month',\n","                             'unemployment', 'unemployment_rate']]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3KOSp8OwDf1q","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RSdukgrpDnoe","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 6: Another way to get the month\n","\n","If you didn't know that casting floats to ints truncates the decimals in Python, you could have used NumPy's `floor()` function. `np.floor` takes an array or Pandas Series of floats as its argument, and returns an array or Series where every float has been rounded down to the nearest whole number. \n","\n","\n","Use `np.floor` to round the values in the \"year_month\" column down so we can cast them as integer years. Note that the types are still floats, so we'll still need to use `astype` to typecast.\n","\n","Store the new `Series` into a variable called `int_years`."]},{"metadata":{"id":"3Z_ExF9MDiMo","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7cfMjA22Dwv8","colab_type":"code","colab":{}},"cell_type":"code","source":["# select the \"year_month\" column and store it in a variable called year_month\n","\n","\n","# use np.floor on year_month to get the years as floats. \n","# Store that on years_by_floor\n","\n","\n","# cast years_by_floor to integers using astype(int)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C5yIBABTEB0r","colab_type":"code","colab":{}},"cell_type":"code","source":["# This code will check that your variable int_years has thesamee answers \n","# as our first approach. This should return True\n","(unemployment['year_month'].astype(int) == int_years).all()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xwmdu5nLEWJ5","colab_type":"text"},"cell_type":"markdown","source":["The last line of code in the previous cell does an element-wise comparison of the values in the corresponding arrays. The `.all()` method checks whether *all* elements are `True`."]},{"metadata":{"id":"P75BcTFKEY_j","colab_type":"text"},"cell_type":"markdown","source":["<a id='section4'></a>\n","## 4. Merging"]},{"metadata":{"id":"I6cUE72NEbSF","colab_type":"text"},"cell_type":"markdown","source":["So far, our `DataFrame` is organized in a reasonable way. But, we know we can do better. We're eventually going to be interested in the unemployment rate for each country. The trouble is, we don't exactly know what the values in `country` refer to in our `unemployment` `DataFrame`. We have all the necessary information in our `countries` `DataFrame`."]},{"metadata":{"id":"W8t3d1VREXNo","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M4tJxI2BEmvM","colab_type":"code","colab":{}},"cell_type":"code","source":["countries.head(3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uVQ_suskE_wi","colab_type":"text"},"cell_type":"markdown","source":["This file has lots of useful information. It even has the country names is three different languages.\n","\n","Because the data we need is stored in two separate files, we'll want to merge the data somehow. Let's determine which column we can use to join this data. `country` looks like a good option. However, we don't need all of the columns in the `countries` `DataFrame`. To select certain columns, we use the name bracket notation we used to reorder the columns."]},{"metadata":{"id":"OEbLe2B5E5pd","colab_type":"code","colab":{}},"cell_type":"code","source":["# Store into country_names the columns country, country_group and name_en of \n","# the countries DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xV2XdKu-FFTI","colab_type":"code","colab":{}},"cell_type":"code","source":["# Print the three first rows of the country_names DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8qzp1FNXFMmr","colab_type":"text"},"cell_type":"markdown","source":["You should be seing this:\n","\n",">![country_names](https://raw.githubusercontent.com/oxanozaep/pandas_learning/master/images/merging_dataframes.jpg)\n","\n","`pandas` includes an easy-to-use merge function. If we wanted to **merge the two `DataFrame`s on country code.** we would need to use the following code:\n","\n","```\n","unemployment = pd.merge(unemployment, country_names, on='country')\n","```"]},{"metadata":{"id":"IrocN23tFSl1","colab_type":"text"},"cell_type":"markdown","source":["Merging is often more complex than this example. If you want to merge on multiple columns, you can pass a list of column names to the `on` parameter.\n","\n","```\n","pd.merge(first, second, on=['name', 'id'])\n","```\n","\n","For more information on merging, check the [documentation](http://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging).\n","\n","`pandas` also provides a `.merge()` method that can act on a `DataFrame`. You can read more about that [here](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html)."]},{"metadata":{"id":"KHve0n0FGXWQ","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 7: Merge on different columns\n","\n","You may sometimes need to merge on columns with different names. To do so, use the `left_on` and `right_on` parameters, where the first listed `DataFrame` is the \"left\" one and the second is the \"right.\" It might look something this.\n","\n","```\n","pd.merge(one, two, left_on='city', right_on='city_name')\n","```\n","\n","Suppose we wanted to merge `unemployment` with a new DataFrame called `country_codes`, which is a subset of columns of country_names containing only country and name, but where the country column is renamed to \"c_code\"."]},{"metadata":{"id":"nyOKTxvBFLgl","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create the DataFrame country_codes, with columns country and name_en from \n","# country_names. Rename the column country to c_code"],"execution_count":0,"outputs":[]},{"metadata":{"id":"og756--PPmvz","colab_type":"text"},"cell_type":"markdown","source":["Use `merge` to merge `unemployment` and `country_codes` on their country codes. Make sure to specify `left_on=` and `right_on=` in the call to `merge`!"]},{"metadata":{"id":"cLWb1qXBOn0u","colab_type":"code","colab":{}},"cell_type":"code","source":["# Merge unemployment and country_codes that you just created on \n","# country and c_code, into a new DataFrame called unemployment_merged\n","\n","\n","# Print the first 5 rows of the unemployment_merged DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SJ9t6eb3EcXL","colab_type":"text"},"cell_type":"markdown","source":["This is what your result should look like:\n","\n","> ![Challenge 7](https://raw.githubusercontent.com/oxanozaep/pandas_learning/master/images/challenge7.jpg)"]},{"metadata":{"id":"RgT3iqTWQTGj","colab_type":"text"},"cell_type":"markdown","source":["<a id='section5'></a>\n","## 5. Calculating Unique and Missing Values"]},{"metadata":{"id":"aH61yoqT8o3g","colab_type":"text"},"cell_type":"markdown","source":["You should be seing this as the result from the previous cell:"]},{"metadata":{"id":"Dmz_PSiyPpTa","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_merged.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O25zEa3OQZao","colab_type":"text"},"cell_type":"markdown","source":["That's easier to understand. We now know that the abbreviation \"at\" corresponds to Austria. We might be curious to check what countries we have data for. The `Series` object includes a `.unique()` method. We'll use this to check the countries. We can select the name either using bracket or dot notation. (While we suggested using brackets above, it *is* sometimes easier to use dot notation. Just be careful.)"]},{"metadata":{"id":"zt1NKgCoQVd4","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use the .unique() method on the column name_en of unemployment_merged"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v0QrC_V-Qqst","colab_type":"text"},"cell_type":"markdown","source":["You should have seen the 30 different names in the column, but to get an easier count of the **number of unique countries,** we can either wrap the above code with `len()` to get the number of items in the array, or we can use the  `Series.nunique()` method. If we apply it to the whole `DataFrame` instead to a particular column `Series`, we get the number of unique values in each column."]},{"metadata":{"id":"8LqkKvVtQfCH","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use the .nunique() method on the whole DataFrame to see the number \n","# of different values in each column"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WbjClORnRDah","colab_type":"text"},"cell_type":"markdown","source":["It might be more interesting to know **how many observations** we actually have. `pandas` has a `Series` method called `.value_counts()` that returns the counts for the unique values in the `Series`."]},{"metadata":{"id":"QEp40oVsQtTW","colab_type":"code","colab":{}},"cell_type":"code","source":["# Call the method .value_counts on the column name_en to see the \n","# number of occurrences of each country."],"execution_count":0,"outputs":[]},{"metadata":{"id":"luTRTc6kROPS","colab_type":"text"},"cell_type":"markdown","source":["Your result has been ordered by default, since the `Series` is sorted by values. If you'd like it sorted by index&mdash;country name in this case&mdash;append the `.sort_index()` method."]},{"metadata":{"id":"aaoZ35L7RHEs","colab_type":"code","colab":{}},"cell_type":"code","source":["# Append to the previous command the method .sort_index() to \n","# get an alphabetically ordered list of occurrences"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iXS9JS1vRYPT","colab_type":"text"},"cell_type":"markdown","source":["This will be useful for our future analysis. The maximum number of observations for a given country for this time period is 1,008 observations. We'll note that certain countries, such as Turkey, have far less data.\n","\n","How about finding the **date range** for this data set? Use the `max()` and `min()` methods on the column year to learn how the minimum and maximum years in our dataset are 1983 and 2010."]},{"metadata":{"id":"9Yn6n9tZRThL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Print the maximum and minimum values with .max() and .min() of \n","# the column year of our unemployment_merged DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FZKodcEOR7RB","colab_type":"text"},"cell_type":"markdown","source":["Next, we should pause for a moment and think about what data we really care about. For our purposes, the variable of interest is `unemployment_rate`. The number of observations by country only reflect the number of instances of each country name in the dataset. It is possible, maybe even expected, to have some missing data within those instances. Let's find out **how many unemployment rate values are missing.**\n","\n","The `.isnull()` method returns a corresponding boolean value for each entry in the unemployment rate `Series`. In Python `True` is equivalent to 1 and `False` is equivalent to 0. Thus, when we add the result (with `.sum()`), we get a count for the *total* number of missing values."]},{"metadata":{"id":"HIZusP3iRfv2","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get the number of nulls in the column unemployment_rate \n","# with .isnull() and add the result with .sum()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zO2CiokZSKhG","colab_type":"text"},"cell_type":"markdown","source":["You should see that there are 945 empty unemployment rate entries."]},{"metadata":{"id":"lSmSqRYuSkjS","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 8: Exploring unemployment rates\n","\n","What are the minimum and maximum unemployment rates in our data set? Which unemployment rates are most and least common?\n","\n","Hint: look at where we found the minimum and maximum years for a hint to the first question, and use `value_counts` for the second."]},{"metadata":{"id":"-EyDYg-MSFIt","colab_type":"code","colab":{}},"cell_type":"code","source":["# Print the minimum and maximum unemployment rate"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xRc2vNNfFe-a","colab_type":"text"},"cell_type":"markdown","source":["You should discover that the unemployment rate ranges from 1.1% to 20.9%"]},{"metadata":{"id":"bLwe72DAStSn","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get the 5 most common unemployment rates."],"execution_count":0,"outputs":[]},{"metadata":{"id":"6JA8p7F8F0iz","colab_type":"text"},"cell_type":"markdown","source":["You should see how the 5 most common unemployment rate are all between 7% and 8%, and that all 5 cases have more than 250 occurrences."]},{"metadata":{"id":"tNreQ3NbSv4O","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use describe() on the unemployment_rate column to understand it a bit more"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cD2hXHEMS-PU","colab_type":"code","colab":{}},"cell_type":"code","source":["# Plot the histogram of the column with the method .hist(). \n","# Also, include the argument bins=20 to get a more granular view"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cwSAGbJeGXzI","colab_type":"text"},"cell_type":"markdown","source":["You should see a histogram similar to the next image:\n","\n",">![Challenge 8](https://raw.githubusercontent.com/oxanozaep/pandas_learning/master/images/challenge8.png)"]},{"metadata":{"id":"S-xH96viTN38","colab_type":"text"},"cell_type":"markdown","source":["<a id='section6'></a>\n","## 6. GroupBy"]},{"metadata":{"id":"_jR8Mc4pTYMt","colab_type":"text"},"cell_type":"markdown","source":["What if we want to know how many missing values exist at the *country* level? We can take the main part of what we had above and create a new column in the `DataFrame`."]},{"metadata":{"id":"KsQDR5tbTAEp","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a new column named unemployment_rate_null in unemployment_merged to \n","# store if the column unemployment_rate is null by applying the .isnull()\n","# method on that column"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v8aKMokZTz7M","colab_type":"text"},"cell_type":"markdown","source":["To count the **number of missing values for each country,** we introduce the `.groupby()` method."]},{"metadata":{"id":"ZD4lOkmtTx6b","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_merged.groupby('name_en')['unemployment_rate_null'].sum()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iNmPCgb2UBVw","colab_type":"text"},"cell_type":"markdown","source":["Let's explain what just happened. We start with our `DataFrame`. We tell `pandas` that we want to group the data by country name&mdash;that's what goes in the parentheses. Next, we need to tell it what column we'd like to perform the `.sum()` operation on. In this case, it's the indicator for whether or not the unemployment rate was missing.\n","\n","As we saw above, the number of records for each country differs. We might, then, want to have the **missing values by country shown as percentages.** Let's create a new `DataFrame` for this.\n","\n","We'll take the code from above and set the `as_index` parameter to `False` to extract the index into a new column."]},{"metadata":{"id":"1XuY-Ct7T85O","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_rate = unemployment_merged.groupby('name_en', as_index=False)['unemployment_rate_null'].sum()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GBodLL8GUPUc","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_rate.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aRZRbg6mUXU-","colab_type":"text"},"cell_type":"markdown","source":["Now, `unemployment_rate` is a `DataFrame` with the information of number of null unemployment rate entries per country. It's important to note that using `as_index=False` in `.groupby()` only works if the grouping column(s) are not the same as the columns on which we're performing the operation.\n","\n","Also, to group by several columns, simply pass in a list of column names to `.groupby()`.\n","\n","```\n","unemployment_merged.groupby(['name_en', 'seasonality'])['unemployment_rate'].mean()\n","```\n","\n","Now, let's add the number of observations by country to the `DataFrame`."]},{"metadata":{"id":"pP2qXgASUT-Z","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_rate['n_obs'] = unemployment_merged.groupby('name_en')['name_en'].count().values"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iqXKbElXU8CS","colab_type":"text"},"cell_type":"markdown","source":["Here, we need to use the `values` attribute to get an array of the counts. Excluding `values` will result in a column full of `NaN`s. This is because the index in `unemployment.groupby('name_en')['name_en'].count()` is a list of the country names. When creating a new column, `pandas` tries to match on index. Recall that the default index values for a `DataFrame` is a sequence of integers.\n","\n","Because we know (or have noticed) that the `.groupby()` function returns the values in alphabetical order, we can simply set the new column to the list of values, as we have done. You can, however, be more explicit and create another `DataFrame` and merge on country name.\n","\n","Finally, let's create the column for the percentage of missing values."]},{"metadata":{"id":"l25zsL4XU2OU","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_rate['null_percentage'] = unemployment_rate['unemployment_rate_null'] / unemployment_rate['n_obs']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_gYThk3rVULS","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_rate"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FpmoYrKXWT8c","colab_type":"text"},"cell_type":"markdown","source":["You can see how Croatia has the highest null employment entries percentage in our dataset with a 66.67% nulls rate."]},{"metadata":{"id":"E87l_0ocVZdI","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 9: GroupBy \n","\n","Find the average unemployment rate for European Union vs. non-European Union countries. \n","\n","1. use `groupby` to group on \"country_group\"\n","2. select the \"unemployment_rate\" column\n","3. use `.mean()` to get the average"]},{"metadata":{"id":"zaT6MZdpVVlL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Merge in the unemployment_merged DataFrame and the country_names DataFrame\n","# into the unemployment DataFrame\n","\n","\n","# Aggregate the unemployment_rate of the unemployment DataFrame\n","# by country_group and apply the mean() method\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HflJaEMlV8HF","colab_type":"text"},"cell_type":"markdown","source":["You should find that EU countries have an average of 8.30% unemployment rate vs the 6.08% of non-EU countries."]},{"metadata":{"id":"zCUHKWCZWKEO","colab_type":"text"},"cell_type":"markdown","source":["<a id='section7'></a>\n","## 7. Exporting A DataFrame to csv\n","\n","As we can see above, Croatia has lots of missing data. This `DataFrame` contains useful information&mdash;things to consider&mdash;when analyzing the data.\n","\n","Suppose we wanted to save this as a .csv file. For this, we'd use the `.to_csv()` method."]},{"metadata":{"id":"4jT-5kAUVmDE","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_rate.to_csv('unemployment_rate.csv')\n","files.download(\"unemployment_rate.csv\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ty4yG5V1Xv1j","colab_type":"text"},"cell_type":"markdown","source":["Open your file. By default, this method writes the indices. We probably don't want that. Let's edit the code. Let's also be explicit about the type of delimiter we're interested in. (Values can be separated by pipes (`|`), semicolons (`;`), tabs (`\\t`), etc.)"]},{"metadata":{"id":"_pWLgW0EXSES","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_rate.to_csv('unemployment_missing.csv', index=False, sep=';')\n","files.download(\"unemployment_missing.csv\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LTMdtdiuYDv6","colab_type":"text"},"cell_type":"markdown","source":["Much better!\n","\n","Let's return to our main `DataFrame`. Now that we have the missing values information in `unemployment_rate`, we can **drop the last column** we added to `unemployment`."]},{"metadata":{"id":"UqLUwS5gX43q","colab_type":"code","colab":{}},"cell_type":"code","source":["# Drop the unemployment_rate_null column with the drop() method in \n","# the unemployment DataFrame."],"execution_count":0,"outputs":[]},{"metadata":{"id":"m_SywQO7YJup","colab_type":"text"},"cell_type":"markdown","source":["It's important to specify the `axis` parameter. `axis=1` refers to columns (`axis=0` refers to rows.) The parameter `inplace=True` simply modifies the actual `DataFrame` rather than returning a new `DataFrame`."]},{"metadata":{"id":"_Axh5eeUYHYb","colab_type":"code","colab":{}},"cell_type":"code","source":["# Print the first rows of the unemployment DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S04wtQKSnLH4","colab_type":"text"},"cell_type":"markdown","source":["Your unemployment `DataFrame` should look like this:\n","\n",">![Exporting a DataFrame](https://raw.githubusercontent.com/oxanozaep/pandas_learning/master/images/exporting-dataframes.jpg)"]},{"metadata":{"id":"m-vT6dqzZh-f","colab_type":"text"},"cell_type":"markdown","source":["<a id='section8'></a>\n","## 8. Dealing With Missing Values: Boolean Indexing\n","\n","Now that we know about the missing values, we have to deal with them. There are two main options:\n","\n","* Fill the missing values with some other values.\n","* Do not use observations with missing values.\n","    * Depending on the analysis, we may want to exclude entire countries.\n","    \n","Because countries with missing unemployment rate data have at least 36 missing values, which is too many to fill, we'll take the second approach and **exclude missing values** from our primary analyses.\n","\n","Instead of just getting rid of that data, it might make sense to store it in a separate `DataFrame`. This way, we could answer questions such as, \"do missing values occur during certain months (or years) more frequently?\" With this, we will introduce the concept of *boolean indexing* for filtering data."]},{"metadata":{"id":"tXqrXpF1YMwX","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_rate_missing = unemployment[unemployment['unemployment_rate'].isnull()]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bx01pVH5Zz6H","colab_type":"text"},"cell_type":"markdown","source":["Recall that `unemployment['unemployment_rate'].isnull()` produces an array of boolean values that we use to filter the unemployment `DataFrame`. We used this previously when counting the number of missing values, though we did not see its output. Let's see some of that now."]},{"metadata":{"id":"2iB4Ki7sZw1b","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment['unemployment_rate'].isnull()[:10]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JOPyESnTuLSb","colab_type":"text"},"cell_type":"markdown","source":["To create `unemployment_rate_missing`, we're indexing `unemployment` with the array above. This returns only the rows where the value in the array is `True`. Let's see if it worked."]},{"metadata":{"id":"tSNNnGUlZ5ap","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment_rate_missing.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Kr5yKS-nueV5","colab_type":"text"},"cell_type":"markdown","source":["It is also possible to specify multiple conditions using the `&` operator, but each condition needs to be inside of parentheses. The `.isin()` method, which takes a `list` of values, is useful when you're interested in conditioning on multiple values on a given column. For example, if you want to select multiple countries.\n","\n","Now, we're ready to remove the missing data in `unemployment`. To do this, we can use the `.dropna()` method."]},{"metadata":{"id":"BCZA3S0BuPqt","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.dropna(subset=['unemployment_rate'], inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8bEpsK36upCs","colab_type":"text"},"cell_type":"markdown","source":["(Note that while we have dropped all observations for which `unemployment_rate == NaN`, this doesn't mean that all of our observations overlap exactly in time. We may find that there are dates where we have data for one country and no data for others.)"]},{"metadata":{"id":"5wulA5mzup4p","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 10: Boolean Indexing\n","Suppose we only want to look at unemployment data from the year 2000 or later. Use **Boolean indexing** to create a DataFrame with only these years.\n","\n","1. Select the \"year\" column from `unemployment`\n","2. Using the year data, create a **mask**: an array of Booleans where each value is True if and only if the year is 2000 or later. Remember, you can use Boolean operators like `>`, `<`, and `==` on a column\n","3. Use the mask from step 2 to index `unemployment`"]},{"metadata":{"id":"pxG0nxQCutPZ","colab_type":"code","colab":{}},"cell_type":"code","source":["# select the year column from unemployment and store it \n","# in a new variable called 'year'\n","\n","\n","# create a mask where year >= 2000\n","\n","\n","# Use the Boolean index on the unemployment DataFrame and store\n","# in the variable unemployment_2000later the result\n","\n","\n","# Print the first few rows of unemployment_2000later\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8TvYUwWCmnVM","colab_type":"text"},"cell_type":"markdown","source":["The result of your `unemployment_2000later` `DataFrame` should look like this:\n","\n","> ![Challenge 10](https://raw.githubusercontent.com/oxanozaep/pandas_learning/master/images/challenge10.jpg)"]},{"metadata":{"id":"za315Sjguy_y","colab_type":"text"},"cell_type":"markdown","source":["<a id='section9'></a>\n","## 9. Sorting Values\n","\n","At this point, you might be curious to know what the highest unemployment rates were. For this, we'll use the `DataFrame.sort_values()` method to **sort the data.**"]},{"metadata":{"id":"zYCNrPiju0r-","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.sort_values('unemployment_rate', ascending=False)[:5]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SCSar2Lou2RV","colab_type":"text"},"cell_type":"markdown","source":["The above code creates a copy of the `DataFrame`, sorted in *descending* order, and prints the first five rows, without assigning that result to any `DataFrame`.\n","\n","You may have noticed that the data set includes a `seasonality` column, which we haven't yet discussed. The unemployment rate in this data is actually calculated in three separate ways. Let's look at the values."]},{"metadata":{"id":"URAV0aFou3nM","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment['seasonality'].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZGAIHUyFu4Cg","colab_type":"text"},"cell_type":"markdown","source":["The three options above correspond to:\n","\n","* not seasonally adjusted\n","* seasonally adjusted\n","* trend cycle\n","\n","We'll stick with seasonally adjusted data so that the values are more comparable. Let's look at the highest unemployment rates in this context."]},{"metadata":{"id":"m0E0_iV5u6iB","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment[unemployment['seasonality'] == 'sa'].sort_values('unemployment_rate', ascending=False)[:5]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1zKx30Gpu65_","colab_type":"text"},"cell_type":"markdown","source":["Spain has the highest seasonally adjusted unemployment rate."]},{"metadata":{"id":"w3du7CF2oyQU","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 11: Sorting based on multiple columns\n","Sometimes you may need to sort based on more than one column, in ascending or descending orders, and are interested only in a subset of the `DataFrame` columns. Let's try with some sorting and boolean indexing to get the summer unemployment rates of the eu countries, ordered by time.\n","\n","1. Create three different boolean indices to select only:\n","  * EU countries\n","  * Summer months (June, July and August)\n","  * Seasonally adjusted unemployment rates\n","2. Store the result in a new `DataFrame` called \"filtered_unemployment\" and print the first 5 rows.\n","3. Using only the columns \"name_en\", \"month\", \"year\" and \"unemployment_rate\", sort the \"filtered_unemployment\" `DataFrame` by year, montn and country name with ascending order. Look at the result image to make sure that the column order and the sorting is identical to yours.\n"]},{"metadata":{"id":"sLUaiujlqPkV","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create the three boolean indices\n","\n","\n","# Use the boolean indices to filter the unemployment DataFrame into the\n","# new DataFrame filtered_unemployment\n","\n","\n","# Print the first 5 rows of filtered_unemployment\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zS2L-LBWtV_d","colab_type":"text"},"cell_type":"markdown","source":["Your datafram should look like this at this point:\n","\n",">![Challenge 11-1](https://raw.githubusercontent.com/oxanozaep/pandas_learning/master/images/challenge11-1.jpg)"]},{"metadata":{"id":"71uqpuatrZxt","colab_type":"code","colab":{}},"cell_type":"code","source":["# Sort the filtered_unemployment by year, month and name_en in ascending order. \n","# Print only the FIRST 5 rows of the columns name_en, month, year and \n","# unemployment_rate in that order"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Kc4a5G8FvGff","colab_type":"text"},"cell_type":"markdown","source":["The first 5 rows should be like these:\n",">![Challenge11-2](https://raw.githubusercontent.com/oxanozaep/pandas_learning/master/images/challenge11-2.jpg)"]},{"metadata":{"id":"BTNCRByfsIoc","colab_type":"code","colab":{}},"cell_type":"code","source":["# Sort the filtered_unemployment by year, month and name_en in ascending order. \n","# Print only the LAST 5 rows of the columns name_en, month, year and \n","# unemployment_rate in that order"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iYrkgkfyvOJb","colab_type":"text"},"cell_type":"markdown","source":["The last 5 rows should be like these:\n",">![Challenge11-3](https://raw.githubusercontent.com/oxanozaep/pandas_learning/master/images/challenge11-3.jpg)"]},{"metadata":{"id":"VU-znJVAu88b","colab_type":"text"},"cell_type":"markdown","source":["<a id='section10'></a>\n","## 10. Plotting With Pandas\n","\n","The best way to get a sense of this data is to **plot it.** Next, we'll start to look at some basic plotting with `pandas`. Before we begin, let's sort the data by country and date. This is good practice and is especially important when using `pandas`'s `.plot()` method because the x-axis values are based on the indices so the graph could make no sense at all if it's not ordered. When we sort, the index values remain unchanged. Thus, we need to reset them. The `drop` parameter tells `pandas` to construct a `DataFrame` *without* adding a column."]},{"metadata":{"id":"qAgoifK4vBY5","colab_type":"code","colab":{}},"cell_type":"code","source":["unemployment.sort_values(['name_en', 'year_month'], inplace=True)\n","unemployment.reset_index(drop=True, inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y4gBb4BJvDkt","colab_type":"text"},"cell_type":"markdown","source":["Let's take a look at Spain's unemployment rate (only because it was the highest) across time."]},{"metadata":{"id":"N9btvHP4u_jB","colab_type":"code","colab":{}},"cell_type":"code","source":["spain = unemployment[(unemployment['name_en'] == 'Spain') &\n","                     (unemployment['seasonality'] == 'sa')]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bFWvLaQxzZti","colab_type":"text"},"cell_type":"markdown","source":["We'll use the `plot()` method changing the attributes of figure size and line color via their arguments. Note that we use a semicolon (**;**) at the end of the line, to avoid printing the name of the object that is returned when we execute that line."]},{"metadata":{"id":"k5x7cKxzvGDT","colab_type":"code","colab":{}},"cell_type":"code","source":["spain['unemployment_rate'].plot(figsize=(10, 8), color='#348ABD');"],"execution_count":0,"outputs":[]},{"metadata":{"id":"auSC-19wvH-Q","colab_type":"text"},"cell_type":"markdown","source":["Note that the values along the x-axis represent the indices associated with Spain in the sorted `unemployment` `DataFrame`. Wouldn't it be nice if, instead, we could **show the time period** associated with the various unemployment rates for Spain? It might also be interesting to **compare** Spain's unemployment rate with its neighbor to the west, Portugal.\n","\n","Let's first create a `DataFrame` that contains the unemployment data for both countries."]},{"metadata":{"id":"08xignGkvITa","colab_type":"code","colab":{}},"cell_type":"code","source":["ps = unemployment[(unemployment['name_en'].isin(['Portugal', 'Spain'])) &\n","                  (unemployment['seasonality'] == 'sa')]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K7n743NbvK_w","colab_type":"text"},"cell_type":"markdown","source":["Next, we'll **generate time series data** by converting our years and months into `datetime` objects. `pandas` provides a `to_datetime()` function that makes this relatively simple. It converts an argument&mdash;a single value or an array of values&mdash;to `datetime`. (Note that the return value [depends on the input](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html).) If we were interested in March 23, 1868, for example, we could do the following."]},{"metadata":{"id":"vqIYa9jevLdY","colab_type":"code","colab":{}},"cell_type":"code","source":["pd.to_datetime('1868/3/23')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n85-mGi3vNz1","colab_type":"text"},"cell_type":"markdown","source":["The argument doesn't necessarily have to be specified in the `yyyy/mm/dd` format. You could list it as `mm/dd/yyyy`, but it's a good idea to be explicit. As a result, we pass in a valid string format."]},{"metadata":{"id":"3Q81IUJmvO5M","colab_type":"code","colab":{}},"cell_type":"code","source":["pd.to_datetime('3/23/1868', format='%m/%d/%Y')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OpFfOXjWvQcd","colab_type":"text"},"cell_type":"markdown","source":["Let's create the `datetime` object and add it to the `DataFrame` as a column named `date`. For this, we'll use the `DataFrame.insert()` method."]},{"metadata":{"id":"Lz1BFVECvRvw","colab_type":"code","colab":{}},"cell_type":"code","source":["ps.insert(loc=0, column='date',\n","          value=pd.to_datetime(ps['year'].astype(str) + '/' +\n","                               ps['month'].astype(str) + '/1'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NEPxsM20vTZB","colab_type":"text"},"cell_type":"markdown","source":["Finally, let's only keep certain columns, rename them, and reshape the `DataFrame`. With the `pivot()` method we can convert the single values of an Index or column, in our case \"Country\" into different columns."]},{"metadata":{"id":"Sv-Cjb4DvTuq","colab_type":"code","colab":{}},"cell_type":"code","source":["ps = ps[['date', 'name_en', 'unemployment_rate']]\n","ps.columns = ['Time Period', 'Country', 'Unemployment Rate']\n","ps = ps.pivot(index='Time Period', columns='Country', \n","              values='Unemployment Rate')\n","ps.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nU6XDU-IvVn6","colab_type":"code","colab":{}},"cell_type":"code","source":["ps.tail()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZvDgmxXxvV8u","colab_type":"text"},"cell_type":"markdown","source":["Notice the indices."]},{"metadata":{"id":"ZTOkdW43vXuj","colab_type":"code","colab":{}},"cell_type":"code","source":["ps.plot(figsize=(10, 8), title='Unemployment Rate\\n');"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ExjTtsFUvau9","colab_type":"text"},"cell_type":"markdown","source":["### Challenge 12: Plot without missing values\n","Note that there are some dates for which we lack data on Spain's unemployment rate. What could you do if you wanted your plot to show only dates where both Spain and Portugal have a defined unemployment rate?"]},{"metadata":{"id":"jFZiJv-bvc4Y","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a new DataFrame without rows that have NaN values. \n","# Print the shape property to check the shape of that DataFrame"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UDKFE3jv2u9X","colab_type":"code","colab":{}},"cell_type":"code","source":["ps.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FbvADsts2fSk","colab_type":"text"},"cell_type":"markdown","source":["You must have seen that, dropping NAs, we end up with a `DataFrame` with 297 rows and 2 columns, as oposed to the original `DataFrame` from above, that had 336 rows and 2 columns."]},{"metadata":{"id":"hvzqyKqavfGw","colab_type":"code","colab":{}},"cell_type":"code","source":["# Plot the DataFrame just created with no missing values"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w-qDMyTp2_fR","colab_type":"text"},"cell_type":"markdown","source":["Your plot should look like this:\n","\n",">![Challenge 12](https://raw.githubusercontent.com/oxanozaep/pandas_learning/master/images/Spain-Portugal_plot.png)"]}]}